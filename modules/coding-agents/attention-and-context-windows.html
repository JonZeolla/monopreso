<section data-transition="none">
  <img src="modules/coding-agents/img/attention_is_all_you_need.png" alt="" width=80% />
  <div class="footnote">
    https://www.youtube.com/watch?v=eMlx5fFNoYc
  </div>
  <aside class="notes">
    Attention in transformers, step-by-step | Deep Learning Chapter 6
    3Blue1Brown
    https://www.youtube.com/watch?v=eMlx5fFNoYc
  </aside>
</section>
<section data-transition="none">
  <img src="modules/coding-agents/img/attention_simple.png" alt="" width=80% />
  <div class="footnote">
    https://www.youtube.com/watch?v=eMlx5fFNoYc
  </div>
  <aside class="notes">
    Attention in transformers, step-by-step | Deep Learning Chapter 6
    3Blue1Brown
    https://www.youtube.com/watch?v=eMlx5fFNoYc
  </aside>
</section>
<section data-transition="none">
  <img src="modules/coding-agents/img/attention_big.png" alt="" width=80% />
  <div class="footnote">
    https://www.youtube.com/watch?v=eMlx5fFNoYc
  </div>
  <aside class="notes">
    Attention in transformers, step-by-step | Deep Learning Chapter 6
    3Blue1Brown
    https://www.youtube.com/watch?v=eMlx5fFNoYc
  </aside>
</section>
<section data-transition="none">
  <img src="modules/coding-agents/img/attention_bigger.png" alt="" width=80% />
  <div class="footnote">
    https://www.youtube.com/watch?v=eMlx5fFNoYc
  </div>
  <aside class="notes">
    Attention in transformers, step-by-step | Deep Learning Chapter 6
    3Blue1Brown
    https://www.youtube.com/watch?v=eMlx5fFNoYc
  </aside>
</section>
<section data-transition="none">
  <img src="modules/coding-agents/img/mathy_attention_workarounds.png" alt="" width=60% />
  <aside class="notes">
    This is essentially a joke picture; I couldn't find a great image to demonstrate grouped query attention, etc.
  </aside>
</section>
